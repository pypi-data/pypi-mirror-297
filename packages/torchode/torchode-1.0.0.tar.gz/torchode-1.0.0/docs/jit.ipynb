{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46327300-b000-4a93-b42a-7caef72e0a59",
   "metadata": {},
   "source": [
    "# JIT Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45feb98e-1972-4600-a3a8-13cc1661a277",
   "metadata": {},
   "source": [
    "torchode is fully JIT compilable. By JIT compiling your model together with the ODE solver, you can speed up your model training as well as inference by eliminating the comparably slow Python interpreter from the forward pass. This means that the actual computations, e.g. matrix multiplication, can be scheduled more quickly and usage of your CPU/GPU increases while the wall-clock time of the computation decreases. However, your model can only be JIT compiled if it is written in [TorchScript](https://pytorch.org/docs/stable/jit.html), a subset of Python.\n",
    "\n",
    "Because of the way PyTorch's JIT works, we can also no longer use the simple `solve_ivp` interface. Instead, we have to construct the solver components ourselves before handing them over to the compiler. This is necessary because the JIT compiler requires that all \"dynamic\" parts of the computation are fixed in place at the time of computation, i.e. after compilation the code can only deal with tensors and literals and not use objects with dynamic behavior such as custom classes.\n",
    "\n",
    "Let's begin by importing everything we need in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c717d8d2-0564-424b-8b63-0bf74395c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchode as to\n",
    "\n",
    "torch.random.manual_seed(180819023);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb44afb-628e-4845-bb4d-3d68bd527ab7",
   "metadata": {},
   "source": [
    "Now we define a simple neural ODE given by an MLP with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8aed13a-a135-4ad7-aa37-f28a9837ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(n_hidden, n_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t, y):\n",
    "        return self.layers(y)\n",
    "\n",
    "n_features = 5\n",
    "model = Model(n_features=n_features, n_hidden=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda2a83-81ee-48c8-93a4-dd6c8c73aa06",
   "metadata": {},
   "source": [
    "Next, we construct the solver components and then put them together into the solver `AutoDiffAdjoint` (that computes the parameter derivatives by backpropagating through the solver). Note how we have to pass the model into the step method and step size controller so that it is fixed when we JIT compile the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a40685-5df1-4f56-b317-cd2e419cbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cpu\")\n",
    "term = to.ODETerm(model)\n",
    "step_method = to.Dopri5(term=term)\n",
    "step_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\n",
    "adjoint = to.AutoDiffAdjoint(step_method, step_size_controller).to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fe243-a4da-4e2d-9c5d-412c83e4bc66",
   "metadata": {},
   "source": [
    "Next, we compile the solver and our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f4cd9a-293a-4feb-a7ec-96c7159016e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjoint_jit = torch.jit.script(adjoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e8b4e-331e-405a-8757-91d179e9da75",
   "metadata": {},
   "source": [
    "As a last step, we have to combine the initial condition `y0` and the evaluation points `t_eval` into a problem instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f4daad-7f05-4ef8-bd84-2fb7758ca9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "t_eval = torch.tile(torch.linspace(0.0, 3.0, 10), (batch_size, 1))\n",
    "problem = to.InitialValueProblem(y0=torch.zeros((batch_size, 5)).to(dev), t_eval=t_eval.to(dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0afd60-c625-4a29-8588-b65553bb4d56",
   "metadata": {},
   "source": [
    "Here we see that both the normal and the compiled solver get the same stats and approximately the same result. The results are not identical because of JIT compilation. Most likely, the compilation reorders some operations that leads to small differences because of the floating point format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7f7b3d-8e6e-49d2-be17-4ebc646216e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_f_evals': tensor([38, 38, 38]), 'n_steps': tensor([6, 6, 6]), 'n_accepted': tensor([6, 6, 6]), 'n_initialized': tensor([10, 10, 10])}\n",
      "{'n_f_evals': tensor([38, 38, 38]), 'n_steps': tensor([6, 6, 6]), 'n_accepted': tensor([6, 6, 6]), 'n_initialized': tensor([10, 10, 10])}\n",
      "Max absolute difference 1.2114644050598145e-05\n"
     ]
    }
   ],
   "source": [
    "sol = adjoint.solve(problem)\n",
    "sol_jit = adjoint_jit.solve(problem)\n",
    "\n",
    "print(sol.stats)\n",
    "print(sol_jit.stats)\n",
    "print(\"Max absolute difference\", float((sol.ys - sol_jit.ys).abs().max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187955b-64e2-4f14-916b-fc2cc0776700",
   "metadata": {},
   "source": [
    "And finally we can compare the two in terms of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c89ef20-9883-4970-a173-0ab35de0fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.63 ms ± 742 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "adjoint.solve(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5375b68-7dac-4594-9a79-09e3bb5abae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A second warm up run. For some reason the second call to the compiled solver triggers more compilation\n",
    "# which we don't want to measure.\n",
    "adjoint_jit.solve(problem);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77ace0f-688b-4384-90fb-8e5ba78e28f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 ms ± 89.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "adjoint_jit.solve(problem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
