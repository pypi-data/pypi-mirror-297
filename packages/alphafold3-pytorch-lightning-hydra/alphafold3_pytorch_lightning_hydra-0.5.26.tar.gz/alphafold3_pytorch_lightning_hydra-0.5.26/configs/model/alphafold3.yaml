_target_: alphafold3_pytorch.models.alphafold3_module.Alphafold3LitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1.8e-3
  betas: [0.9, 0.95]
  eps: 1e-8
  # foreach: false

scheduler:
  _target_: torch.optim.lr_scheduler.LambdaLR
  _partial_: true
  lr_lambda: ${resolve_variable:alphafold3_pytorch.utils.model_utils.default_lambda_lr_fn}
  verbose: true

net:
  target: ${resolve_variable:alphafold3_pytorch.models.components.alphafold3.Alphafold3}
  dim_atom_inputs: 3
  dim_template_feats: 108
  num_dist_bins: 64
  pdb_training_set: true
  diffusion_num_augmentations: 4 # NOTE: must be one of (initial_training: 48, fine_tuning_1: 32, fine_tuning_2: 32, fine_tuning_3: 32), proceeding from left to right following Table 6 in the paper
  plm_embeddings: null # NOTE: if specified, a list of values in (`esm2_t33_650M_UR50D`, `prostT5`)
  nlm_embeddings: null # NOTE: if specified, a list of values in (`rinalmo`)
  constraints: ${data.constraints}

  checkpoint_input_embedding: true
  checkpoint_trunk_pairformer: true
  checkpoint_diffusion_module: true
  checkpoint_distogram_head: true
  checkpoint_confidence_head: true

# training parameters
compile: false # compile model for faster training with PyTorch 2.0
skip_invalid_gradient_updates: true # zero-out invalid gradient updates

# model parameters
parameters_initialized_from: random # NOTE: must be one of (initial_training: 'random', fine_tuning_1: 'initial_training', fine_tuning_2: 'fine_tuning_1', fine_tuning_3: 'fine_tuning_2'), proceeding from left to right following Table 6 in the paper
train_structure_and_distogram: true # NOTE: must be one of (initial_training: True, fine_tuning_1: True, fine_tuning_2: True, fine_tuning_3: False), proceeding from left to right following Table 6 in the paper
train_pae_head: false # NOTE: must be one of (initial_training: False, fine_tuning_1: False, fine_tuning_2: False, fine_tuning_3: True), proceeding from left to right following Table 6 in the paper
diffusion_add_smooth_lddt_loss: true # NOTE: must be one of (initial_training: True, fine_tuning_1: False, fine_tuning_2: False, fine_tuning_3: False), proceeding from left to right
diffusion_add_bond_loss: false # NOTE: must be one of (initial_training: False, fine_tuning_1: True, fine_tuning_2: True, fine_tuning_3: True), proceeding from left to right following Table 6 in the paper

# model selection
is_fine_tuning: false # NOTE: must be one of (initial_training: False, fine_tuning_1: True, fine_tuning_2: True, fine_tuning_3: True), proceeding from left to right following Table 6 in the paper
num_samples_per_example: 5 # NOTE: determines how many samples are generated (and potentially visualized) for each input validation or test example

# visualization parameters
visualize_train_samples_every_n_steps: 0 # NOTE: set to 0 to disable
visualize_val_samples_every_n_steps: 0 # NOTE: set to 0 to disable
visualize_test_samples_every_n_steps: 0 # NOTE: set to 0 to disable
