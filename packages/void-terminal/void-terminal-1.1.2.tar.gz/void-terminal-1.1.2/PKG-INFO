Metadata-Version: 2.1
Name: void-terminal
Version: 1.1.2
Summary: LLM based APIs
Home-page: https://github.com/binary-husky/void-terminal
Author: Qingxu
Author-email: 505030475@qq.com
Project-URL: Bug Tracker, https://github.com/binary-husky/void-terminal/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: fastapi==0.110
Requires-Dist: gradio-client==0.8
Requires-Dist: pypdf2==2.12.1
Requires-Dist: zhipuai==2.0.1
Requires-Dist: tiktoken>=0.3.3
Requires-Dist: requests[socks]
Requires-Dist: pydantic
Requires-Dist: llama-index~=0.10
Requires-Dist: protobuf==3.20
Requires-Dist: transformers<4.42,>=4.27.1
Requires-Dist: scipdf_parser>=0.52
Requires-Dist: anthropic>=0.18.1
Requires-Dist: python-markdown-math
Requires-Dist: pymdown-extensions
Requires-Dist: websocket-client
Requires-Dist: beautifulsoup4
Requires-Dist: prompt_toolkit
Requires-Dist: latex2mathml
Requires-Dist: python-docx
Requires-Dist: mdtex2html
Requires-Dist: dashscope
Requires-Dist: pyautogen
Requires-Dist: colorama
Requires-Dist: Markdown
Requires-Dist: pygments
Requires-Dist: edge-tts
Requires-Dist: pymupdf
Requires-Dist: openai
Requires-Dist: rjsmin
Requires-Dist: loguru
Requires-Dist: arxiv
Requires-Dist: numpy
Requires-Dist: rich

# <div align=center> Void Terminal</div>

The CLI & python API for the well-known project [`gpt_academic`](https://github.com/binary-husky/gpt_academic.git).

# Installation

1. source installation.
```
bash init.bash
```

2. Pip installation (Not recommended).
```
pip install void-terminal
```

# Usage (Commandline)

- Chat

```
vt -a "hello, world!"
```

- Ask about how to do a linux command

```
vt -c "List all docker containers currently running on this system"
```


- Config (For all possible configurations, read [`config.py`](https://github.com/binary-husky/gpt_academic/blob/master/config.py) in the mother project.)
```
# Warning! This will write configuration into .bashrc and change your ENV variables !! Use with caution !! 警告，该命令会修改你的.bashrc文件，持久修改你的环境变量
vt --set_conf API_KEY "sk-123456789123456789123456789"
vt --set_conf LLM_MODEL "gpt-3.5-turbo"
vt --set_conf DEFAULT_WORKER_NUM "20"
```


# Usage (Python API)

- Chat without interaction

```python
import void_terminal as vt
# For more available configurations (including network proxy, api, using chatglm etc.),
# see config.py of in the mother project:
# https://github.com/binary-husky/gpt_academic.git
vt.set_conf(key="API_KEY", value="sk-xxxxxxxxxxxxxx")   # or you can delete this line and set ENV variable
vt.set_conf(key="LLM_MODEL", value="gpt-3.5-turbo")     # or you can delete this line and set ENV variable

chat_kwargs = vt.get_chat_default_kwargs()
chat_kwargs['inputs'] = 'Hello, world!'
result = vt.get_chat_handle()(**chat_kwargs)
print('\n*************\n' + result + '\n*************\n' )
```


- Using mother project's plugin (Example: translate THIS readme file to Chinese)

```python
import void_terminal as vt
from rich.live import Live
from rich.markdown import Markdown

# vt.set_conf(key="API_URL_REDIRECT", value='{"https://api.openai.com/v1/chat/completions": "http://11.22.33.44:5566/v1/chat/completions"}')
vt.set_conf(key="API_KEY", value="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")
vt.set_conf(key="LLM_MODEL", value="gpt-3.5-turbo")

plugin = vt.get_plugin_handle('void_terminal.crazy_functions.Markdown_Translate->TranslateMarkdownToSpecifiedLanguage')
plugin_kwargs = vt.get_plugin_default_kwargs()
plugin_kwargs['main_input'] = './README.md'
my_working_plugin = plugin(**plugin_kwargs)

with Live(Markdown(""), auto_refresh=False) as live:
    for cookies, chat, hist, msg in my_working_plugin:
        md_str = vt.chat_to_markdown_str(chat)
        md = Markdown(md_str)
        live.update(md, refresh=True)
```

- Using mother project's plugin (Example: chat with multiple LLM models)

```python
import void_terminal as vt
from rich.live import Live
from rich.markdown import Markdown

llm_model = "gpt-3.5-turbo&gpt-4"
vt.set_conf(key="API_KEY", value="sk-xxxxxxxxxxxxxx")
vt.set_conf(key="LLM_MODEL", value=llm_model)
plugin = vt.get_plugin_handle('void_terminal.crazy_functions.InquiryMultipleLargeLanguageModels->SimultaneousInquiry')
plugin_kwargs = vt.get_plugin_default_kwargs()
plugin_kwargs['main_input'] = 'Hello, world!'
plugin_kwargs['plugin_kwargs'] = {"advanced_arg": llm_model}
my_working_plugin = plugin(**plugin_kwargs)

with Live(Markdown(""), auto_refresh=False) as live:
    for cookies, chat, hist, msg in my_working_plugin:
        md_str = vt.chat_to_markdown_str(chat)
        md = Markdown(md_str)
        live.update(md, refresh=True)
```

# Advanced Settings with Environment Variables

1. `SHOW_VOID_TERMINAL_LOGS`. Set this Environment Variable to display void terminal logs




