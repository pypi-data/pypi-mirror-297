"""
Public facades:
- PipelineOrchestrator: A facade pattern for all the public services. It is the highest level of abstraction in this package.

Public services:
- PreparatorService: A service for preprocessing data.
- ComponentService: A service for the "components" in this package, and for generating MultiEstimatorPipelines.
- PipelineEvolverService: A service for evolving a MultiEstimatorPipeline to a next-generation pipeline.
- PerformanceService: A service for evaluating the performance of a MultiEstimatorPipeline.

Public classes:
- MultiEstimatorPipeline: A subclass of scikit-learn's Pipeline class. 
  It is a container for the whole pipeline, from preprocessing to prediction. 
  It also adds extra functionality, like housing multiple estimators, updating scores, and assigning weights to estimators from these scores. 
  It can be generated by the ComponentService. The class itself also contains useful documentation.
- Evaluator: A class for evaluating predictions.
- ModelExplainer: A class for explaining features of a model.

Public modules:
- metrics: A utility module for regression and classification metrics. Custom metrics can be added with the static method: PipelineOrchestrator.add_custom_metric.


Examples
--------

EXAMPLE 1: Basic usage of the ComponentService class.
```python
import pandas as pd
from sklearn.model_selection import ShuffleSplit, train_test_split
from sklearn.datasets import make_regression

from orpheus import ComponentService, PipelineEvolverService, MultiEstimatorPipeline

config_path = "./configurations.yaml"

# create a cross validation object. replace with your own cv object
cv_obj = ShuffleSplit(n_splits=3)

# create a synthetic dataset. replace with your own data
X, y = make_regression(
    n_samples=1000,
    n_features=5,
    random_state=42,
)

X = pd.DataFrame(X)
X.columns = [f"feature_{N}" for N in range(1, X.shape[1] + 1)]
y = pd.Series(y)

# split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

if __name__ == "__main__":
    # initialize the compomnentservice.
    # at first runtime, program will create a config file if it doesn't exist yet.
    # you can edit this file to change the settings of all the preprocessing components
    # before running the program again.
    component_service = ComponentService(
        X_train,
        X_test,
        y_train,
        y_test,
        config_path=config_path,
        cv_obj=cv_obj,
        n_jobs=-1,
    )

    # kick off the preprocessing and training process.
    # settings per component are read from the config file and applied
    # to the preprocessing and training process when running this method.
    component_service.initialize(
        scale=True,
        add_features=True,
        remove_features=True,
    )

    # generate fitted pipelines for best base models and stacked models,
    # found by the hyperparameter tuning process.
    # these include the preprocessing steps and estimators.
    pipe_base: MultiEstimatorPipeline = component_service.generate_pipeline_for_base_models(top_n_per_tuner=5)
    pipe_stacked: MultiEstimatorPipeline = component_service.generate_pipeline_for_stacked_models(
        top_n_per_tuner_range=[3, 5]
    )

    # evolve the pipelines through stack generalization
    evolver = PipelineEvolverService(pipe_stacked)
    evolved_pipe_hv = evolver.evolve_voting(n_jobs=4, voting="hard")

    evolved_pipe_hv.fit(X_train, y_train)
    print(evolved_pipe_hv.score(X_test, y_test))

    evolved_pipe_sv = evolver.evolve_voting(n_jobs=4, voting="soft")
    evolved_pipe_sv.fit(X_train, y_train)
    print(evolved_pipe_sv.score(X_test, y_test))

```


EXAMPLE 2: Basic usage of the PipelineOrchestrator class.
```python
import pandas as pd
from sklearn.model_selection import ShuffleSplit, train_test_split
from sklearn.datasets import make_regression
from sklearn.metrics import r2_score

from orpheus import PipelineOrchestrator, MultiEstimatorPipeline

config_path = "./configurations.yaml"

# create a cross-validation object. Replace with your own cv object
cv_obj = ShuffleSplit(n_splits=2)

# create a synthetic dataset. Replace with your own data
X, y = make_regression(
    n_samples=1000,
    n_features=5,
    random_state=42,
)
X = pd.DataFrame(X)
X.columns = [f"feature_{N}" for N in range(1, X.shape[1] + 1)]
y = pd.Series(y)

# split into train and test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

if __name__ == "__main__":
    orchestrator = PipelineOrchestrator(
        X_train,
        y_train,
        metric=r2_score,
        config_path=config_path,
        verbose=3,
        n_jobs=4,
        shuffle=True,
        ensemble_size=0.1,
        validation_size=0.2,
    )

    (
        orchestrator
        .pre_optimize(max_splits=2)
        .build(
            scale=False,
            add_features=False,
            remove_features=False,
        )
        .fortify(
            optimize_n_jobs=True,
            threshold_score=0.90,
            plot_explaining=True,
        )
    )

    # make predictions
    pred_base = orchestrator.pipelines["base"].predict(X_test)
    pred_stacked = orchestrator.pipelines["stacked"].predict(X_test)
    pred_evolved = orchestrator.pipelines["evolved"].predict(X_test)

    # get an overview of the feature importances
    explained_features = orchestrator.get_explained_features()

    # save the pipelines to disk for later use
    orchestrator.pipelines["base"].save("base_pipeline")
    orchestrator.pipelines["stacked"].save("stacked_pipeline")
    orchestrator.pipelines["evolved"].save("evolved_pipeline")

```
"""

from setuptools_scm import get_version

from .services.preparator_service import PreparatorService
from .services.component_service import ComponentService
from .services.performance_service import PerformanceService
from .services.pipeline_evolver_service import (
    PipelineEvolverService,
)
from .services.additional_types.multi_estimator_pipeline import (
    MultiEstimatorPipeline,
)

from .metrics import MetricConverter
from .evaluators import Evaluator, ModelExplainer
from .orchestrator import PipelineOrchestrator, PipelineOrchestratorProxy

from .utils.warnings import _check_sklearn_metrics

_check_sklearn_metrics()

__version__ = get_version(root="../../", relative_to=__file__)

__all__ = [
    "PipelineOrchestrator",
    "PipelineOrchestratorProxy",
    "PreparatorService",
    "ComponentService",
    "PipelineEvolverService",
    "PerformanceService",
    "MultiEstimatorPipeline",
    "Evaluator",
    "ModelExplainer",
    "MetricConverter",
]
