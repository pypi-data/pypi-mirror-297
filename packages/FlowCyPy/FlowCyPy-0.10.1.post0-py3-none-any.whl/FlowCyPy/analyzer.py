
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from typing import List
from MPSPlots.styles import mps
from FlowCyPy.units import second
import warnings
from FlowCyPy.detector import Detector
from FlowCyPy import peak_finder
from FlowCyPy.cytometer import FlowCytometer

import logging
from tabulate import tabulate
from FlowCyPy.report import Report


class Analyzer:
    """
    A class to analyze pulse signals generated by a flow cytometer, extracting features
    such as pulse height, width, and area from the signal.

    Attributes
    ----------
    detectors : List[object]
        List of detector objects for analysis.

    Methods
    -------
    run_analysis(compute_peak_area=True, height_threshold=None):
        Detects and extracts features from signals.
    get_coincidence(margin):
        Returns dataframe where peak times from different detectors match within a given margin.
    find_peaks(detector, peak_area=True, height_threshold=None):
        Detects significant peaks and calculates their features.
    display_features():
        Displays detected features in tabular format.
    plot():
        Plots signals along with detected peaks.
    """

    def __init__(self, cytometer: FlowCytometer, algorithm: peak_finder.BaseClass) -> None:
        """
        Initializes the PeakAnalyzer with a list of detectors.

        Parameters
        ----------
        detectors : List[object]
            A list of detector objects that contain time and signal data.
        """
        self.algorithm = algorithm
        self.cytometer = cytometer
        self.datasets = []


    def run_analysis(self, compute_peak_area: bool = False) -> None:
        """
        Main method to run the peak analysis on all detectors and extract features like heights, widths,
        areas, and other key statistics.

        Parameters
        ----------
        compute_peak_area : bool, optional
            Whether to compute the area under the peaks, by default False.

        Returns
        -------
        pd.DataFrame
            MultiIndex DataFrame with peak properties for each detector.
        """
        logging.info("Starting peak analysis for all detectors.")

        # Run peak detection on each detector
        self._analyze_all_detectors(compute_peak_area)

        # Calculate and log additional statistics
        self._log_statistics()

    def _analyze_detector(self, detector: Detector, compute_peak_area: bool) -> None:
        """
        Analyzes a single detector by running the peak detection algorithm and extracting peak properties.

        Parameters
        ----------
        detector : object
            The detector object containing signal and time data.
        compute_peak_area : bool
            Whether to compute the area under the peaks.

        Returns
        -------
        pd.DataFrame
            DataFrame containing the peak properties for the analyzed detector.
        """
        logging.info(f"Analyzing Detector {detector.name}.")

        # Run the peak detection algorithm
        self.algorithm.detect_peaks(detector=detector, compute_area=compute_peak_area)

        logging.info(f"Detector {detector.name}: Detected {len(detector.peak_properties)} peaks.")

    def _analyze_all_detectors(self, compute_peak_area: bool) -> None:
        """
        Runs the peak detection on all detectors and returns the combined results.

        Parameters
        ----------
        compute_peak_area : bool
            Whether to compute the area under the peaks.

        """
        for detector in self.cytometer.detectors:
            # Analyze each detector and append the results
            self._analyze_detector(detector, compute_peak_area)

        self.dataframe = pd.concat(
            [d.peak_properties for d in self.cytometer.detectors],
            keys=[f'{d.name}' for d in self.cytometer.detectors]
        )

        self.dataframe.index.names = ['Detector', 'Event']

    def _log_statistics(self) -> None:
        """
        Logs key statistics about the detected peaks for each detector using tabulate for better formatting.
        Includes total events, average time between peaks, first and last peak times, and minimum time between peaks.

        Parameters
        ----------
        combined_results : pd.DataFrame
            The combined DataFrame containing peak properties for all detectors.
        """
        total_peaks = 0
        table_data = []  # List to store table data for each detector

        logging.info("\n=== Analysis Summary ===")

        # Group by the 'Detector' column to calculate stats for each detector
        for detector, (_, group) in zip(self.cytometer.detectors, self.dataframe.groupby('Detector')):
            num_events = len(group)
            total_peaks += num_events

            # Calculate average and minimum time between peaks if more than one event is detected
            if num_events > 1:
                times = group['PeakTimes'].sort_values()
                time_diffs = times.diff().dropna()  # Compute time differences between peaks
                avg_time_between_peaks = time_diffs.mean()
                min_time_between_peaks = time_diffs.min()  # Calculate minimum time difference between peaks
            else:
                avg_time_between_peaks = "N/A"
                min_time_between_peaks = "N/A"

            # Get first and last peak times
            first_peak_time = group['PeakTimes'].min() if num_events > 0 else "N/A"
            last_peak_time = group['PeakTimes'].max() if num_events > 0 else "N/A"

            # Append detector statistics to table data
            table_data.append([
                detector.name,                                  # Detector name
                num_events,                                     # Number of events
                f"{first_peak_time.to_compact():.4~P}",         # First peak time
                f"{last_peak_time.to_compact():.4~P}",          # Last peak time
                f"{avg_time_between_peaks.to_compact():.4~P}",  # Average time between peaks
                f"{min_time_between_peaks.to_compact():.4~P}"   # Minimum time between peaks
            ])

        # Format the table using tabulate
        headers = ["Detector", "Number of Events", "First Peak Time", "Last Peak Time", "Avg Time Between Peaks", "Min Time Between Peaks"]
        formatted_table = tabulate(table_data, headers=headers, tablefmt="grid", floatfmt=".3f")

        # Log the formatted table
        logging.info("\n" + formatted_table)

        # Log total peaks across all detectors
        logging.info(f"\nTotal number of peaks detected across all detectors: {total_peaks}")


    def get_coincidence(self, margin: second.dimensionality) -> None:
        """
        Identifies coincident events between two detectors within a specified time margin.

        Parameters
        ----------
        dataframe : pd.DataFrame
            DataFrame containing peak times for detectors.
        margin : pint.Quantity
            Time margin within which peaks are considered coincident, in compatible time units.

        """

        # Ensure margin has correct dimensionality (time)
        assert margin.dimensionality == second.dimensionality, "Margin must have time dimensionality."

        self.dataframe['PeakTimes'] = self.dataframe['PeakTimes'].pint.to(margin.units)

        # Split the data for Detector_1 and Detector_2
        d0 = self.dataframe.xs(self.cytometer.detectors[0].name, level='Detector')
        d1 = self.dataframe.xs(self.cytometer.detectors[1].name, level='Detector')

        # Repeat and tile PeakTimes for comparison (keeping your protocol)
        d0_repeated = np.repeat(d0['PeakTimes'].values.numpy_data, len(d1)) * margin.units
        d1_tiled = np.tile(d1['PeakTimes'].values.numpy_data, len(d0)) * margin.units

        # Compute time differences and reshape the mask
        time_diffs = np.abs(d0_repeated - d1_tiled)
        mask = time_diffs <= margin
        mask = mask.reshape(len(d0), len(d1))

        # Find indices where coincidences occur
        indices = np.where(mask)

        # Count coincidences per column (for each event in Detector_1)
        true_count_per_column = np.sum(mask.astype(int), axis=0)

        # Warnings and assertions
        if np.all(true_count_per_column == 0):
            warnings.warn("No coincidence events found, the margin might be too low.")

        assert np.all(true_count_per_column <= 1), \
            "Coincidence events are ambiguously defined, the margin might be too high."

        # Extract coincident events from both detectors
        coincident_detector_0 = d0.iloc[indices[0]].reset_index(drop=True)
        coincident_detector_1 = d1.iloc[indices[1]].reset_index(drop=True)

        # Combine the coincident events into a single DataFrame
        combined_coincidences = pd.concat([coincident_detector_0, coincident_detector_1], axis=1)

        # Assign proper MultiIndex column names
        combined_coincidences.columns = pd.MultiIndex.from_product([[d.name for d in self.cytometer.detectors], d0.columns])

        self.coincidence = combined_coincidences

    def display_features(self) -> None:
        """
        Displays extracted peak features for all datasets in a tabular format.
        """
        for i, dataset in enumerate(self.datasets):
            print(f"\nFeatures for Dataset {i + 1}:")
            dataset.print_properties()  # Reuse the print_properties method from DataSet


    def plot_peak(self, show: bool = True, figure_size: tuple = (7, 6)) -> None:
        """
        Plots the signal with detected peaks and widths at half-maximum, if available.
        """
        with plt.style.context(mps):
            n_detectors = len(self.cytometer.detectors)
            _, axes = plt.subplots(ncols=1, nrows=n_detectors, figsize=figure_size, sharex=True)

            for ax, detector in zip(axes, self.cytometer.detectors):
                self.algorithm.plot(detector, ax=ax, show=False)

            plt.tight_layout()

            if show:
                plt.show()

    def plot(self, show: bool = True, log_plot: bool = True) -> None:
        """
        Plots the 2D density plot of the scattering intensities from the two detectors.

        The plot includes:
            - A 2D hexbin density plot.
            - X-axis label positioned on top and y-axis label positioned on the right.
            - A horizontal colorbar at the bottom indicating the density.
        """
        # Reset the index if necessary (to handle MultiIndex)
        df_reset = self.coincidence.reset_index()
        x_data = df_reset[(self.cytometer.detectors[0].name, 'Heights')]
        y_data = df_reset[(self.cytometer.detectors[1].name, 'Heights')]

        # Extract the units from the pint-pandas columns
        x_unit = x_data.pint.units
        y_unit = y_data.pint.units

        import seaborn as sns
        with plt.style.context(mps):

            g = sns.jointplot(
                data=df_reset,
                x=x_data,
                y=y_data,
                kind='kde',
                alpha=0.8,
                fill=True,
                joint_kws={'alpha': 0.7}
            )
            sns.scatterplot(
                data=df_reset,
                x=x_data,
                y=y_data,
                ax=g.ax_joint,
                alpha=0.6,
                zorder=1
            )

            # # Set the x and y labels with units
            g.ax_joint.set_xlabel(f"Heights [{x_unit}]")
            g.ax_joint.set_ylabel(f"Heights [{y_unit}]")

            plt.tight_layout()

            if log_plot:
                ax = g.ax_joint
                ax.set_xscale('log')
                ax.set_yscale('log')
                g.ax_marg_x.set_xscale('log')
                g.ax_marg_y.set_yscale('log')


            if show:
                plt.show()

    def generate_report(self, filename: str) -> None:
        report = Report(
            flow_cell=self.cytometer.scatterer.flow_cell,
            scatterer=self.cytometer.scatterer,
            analyzer=self
        )

        report.generate_report()